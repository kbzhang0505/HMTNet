# HMTNet
After the paper is accepted, we will provide code for the paper: HMTNet: A Hierarchical Multi-Task Network for Super-Resolution Image Quality Assessment.
# Abstract
Super-resolution (SR) image quality assessment (SR-IQA) plays a crucial role in evaluating the performance and optimizing model parameters of SR algorithms. However, most existing SR-IQA methods typically quantify the degradation of SR images through a single-task regression framework to map visual perceptual features to quality scores. Although these methods perform well, they may exhibit bias when evaluating certain SR images. In this paper, we propose a novel hierarchical multi-task framework, called HMTNet, for no-reference super resolution image quality assessment (NR-SRIQA), to measure the quality of SR images in a coarse-to-fine manner. The newly proposed HMTNet first employs a quality grading network which integrates a U-Net and contrastive learning, to divide image quality into five grades coarsely, as the quality grading prior knowledge to conducting qualitative evaluation of SR image quality. Then a triple-perspective Shared Feature Extractor Network (SFEN) that integrates texture details, gradient and saliency features, is developed to build a fine mapping from visual perception features to quantitative quality score guided by the learned quality grading prior knowledge. Under the coarse-to- fine SR-IQA framework, the proposed HMTNet can quantify the degradation of SR images more accurately and comprehensively. Thorough experiments on both QADS and MA datasets indicate that our HMTNet achieves better human visual consistency compared to other state-of-the-art SR-IQA methods.
# The overall framework
